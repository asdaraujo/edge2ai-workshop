= Streams Processing with Apache Flink

In this workshop is build on top of the "edge2AI Workshop" (pre-condition) and add enhanced features in stream processing.

== Labs summary

* *Lab 1* - Count by sensor_id
* *Lab 2* - Filtering on sensor_0 value


[[lab_1, Lab 1]]
== Lab 1 - Apache Flink - Count by sensor_id

. Let's use the #iot stream form the sensors from the previous lab
+
.. *Dataflow:*
+
image::images/iot_streamingFlinkDataflowCount.png[width=800]
+
.. Open two SSH connections to your environment
+
image::images/flink_ssl_lite.png[width=800]
+
let's have look at the code:
+
Local Execution Environment
+
[source,java]
----
// get iot stream from kafka - topic "iot"
    DataStream<String> iotStream = env.addSource(
        new FlinkKafkaConsumer<>("iot", new SimpleStringSchema(), properties));
----
+
Collection Data Sources
+
[source,java]
----
// split and sum on 'sensor_id'
    DataStream<Tuple5<Long, Integer, Integer, Integer, Integer>> aggStream = iotStream
     .flatMap(new trxJSONDeserializer())
     .keyBy(1)
     .window(TumblingProcessingTimeWindows.of(Time.seconds(10)))
     .sum(4) ;
----
+
Iterator Data Sink
+
----
// write the aggregated data stream to a Kafka sink
    aggStream.addSink(new FlinkKafkaProducer<>(
     Commons.EXAMPLE_KAFKA_SERVER,
     "simulation_sum",
     new serializeSum2String()));
----
+
. Let's run the application

+
use the first SSH connection to run the Flink application
+
[source,shell]
----
$ cd /opt/cloudera/parcels/FLINK
$ sudo wget https://github.com/zBrainiac/edge2ailab/releases/download/0.2.1/edge2ailab-0.2.1-jar-with-dependencies.jar -P /opt/cloudera/parcels/FLINK/lib/flink/examples/streaming
$ ./bin/flink run -m yarn-cluster -c FlinkConsumer.iotConsumer -ynm myFirstFlinkApp lib/flink/examples/streaming/edge2ailab-0.2.1-jar-with-dependencies.jar
----
+
. Let's see how the application works
+
.. use the second SSH connection to see the result
+
[source,shell]
----
$ cd /opt/cloudera/parcels/CDH
$ ./bin/kafka-console-consumer --bootstrap-server edge2ai-1.dim.local:9092 --topic simulation_sum
----
+
SSH connection
+
image::images/Kafka_topic_simulation_sum.png[width=800]
+
.. SMM view:
+
image::images/SMM_topic_simulation_sum.png[width=800]
+
.. YARN & FLINK UI view:
+
goto Cloudera Manager > YARN > Applications
+
image::images/YARN_Application.png[width=800]
+
see details of the running Flink job and use the <Tracking URL>
+
image::images/YARN_Application_details.png[width=800]
+
Flink UI provide more details and monitoring of the job
+
image::images/FLINk_running_jobs.png[width=800]


[[lab_2, Lab 2]]
== Lab 2 - Filtering on sensor_0 value
. Letâ€™s use the #iot stream form the sensors from the previous lab
+
.. *Dataflow:*
+
image::images/iot_streamingFlinkDataflowFilter.png[width=800]
Collection Data Sources
+
[source,java]
----
// split on 'sensor_id' & filter on sensor_0
    DataStream<Tuple5<Long, Integer, Integer, Integer, Integer>> aggStream = iotStream
       .flatMap(new trxJSONDeserializer())
       .keyBy(1) // sensor_id
       .sum(4)
       .filter(new FilterFunction<Tuple5<Long, Integer, Integer, Integer, Integer>>() {
          @Override
          public boolean filter(Tuple5<Long, Integer, Integer, Integer, Integer> value) throws Exception {
             return value.f2 >= 50 ; // sensor_0
          }
       });
----
+
. Let's run the application
+
use the new SSH connection to run the Flink application
+
[source,shell]
----
$ cd /opt/cloudera/parcels/FLINK
$ ./bin/flink run -m yarn-cluster -c FlinkConsumer.iotConsumerFilter -ynm myFlinkAppFilter lib/flink/examples/streaming/edge2ailab-0.2.1-jar-with-dependencies.jar
----
+
. Let's see how the application works
+
.. use the second SSH connection to see the result
+
[source,shell]
----
$ cd /opt/cloudera/parcels/CDH
$ ./bin/kafka-console-consumer --bootstrap-server edge2ai-1.dim.local:9092 --topic iot_filter
----